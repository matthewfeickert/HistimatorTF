{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.11/01\n"
     ]
    }
   ],
   "source": [
    "from ROOT import TVirtualFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fptype = tf.float64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting with TensorFlow + Minuit\n",
    "First we define a few helpers to handle the estimators parameters etc. This is usually integral in programs like TensorFlowAnalysis or RooFit. Later we define a model using these tools. Finally we run the graph and minimise using Minuit\n",
    "\n",
    "\n",
    "## Estimators and MC tools\n",
    "\n",
    "### Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimate the maximum of density function defined as a graph:\n",
    "- **density** : density function\n",
    "- **phsp** : phase space object (should have UniformSample method implemented)\n",
    "- **size** : size of the random sample for maximum estimation\n",
    "- **sess** : TF session\n",
    "- **pdf**  : density graph\n",
    "- **x**    : phase space placeholder used for the definition of the density function                     \n",
    "- **size** : size of the random sample for maximum estimation                                            \n",
    "\n",
    "Returns the estimated maximum of the density                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaximumEstimator(density, phsp, size) :\n",
    "    sample = phsp.UniformSample(size)\n",
    "    return tf.reduce_max(density(sample))\n",
    "def EstimateMaximum(sess, pdf, x, norm_sample) :\n",
    "    pdf_data = sess.run(pdf, { x : norm_sample } )\n",
    "    return np.nanmax( pdf_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FitParameter(tf.Variable) :\n",
    "    def __init__(self, name, init_value, lower_limit = 0., upper_limit = 0., step_size = 1e-6) :\n",
    "        tf.Variable.__init__(self, init_value, dtype = fptype)\n",
    "        self.init_value = init_value\n",
    "        self.par_name = name\n",
    "        self.step_size = step_size\n",
    "        self.lower_limit = lower_limit\n",
    "        self.upper_limit = upper_limit\n",
    "        self.placeholder = tf.placeholder(self.dtype, shape=self.get_shape())\n",
    "        self.update_op = self.assign(self.placeholder)\n",
    "        self.prev_value = None\n",
    "        self.error = 0.\n",
    "        self.fitted_value = 0.\n",
    "    def update(self, session, value) :\n",
    "        if value != self.prev_value :\n",
    "            session.run( self.update_op, { self.placeholder : value } )\n",
    "            self.prev_value = value\n",
    "\n",
    "    def floating(self) :\n",
    "        return self.step_size > 0\n",
    "    def randomise(self, session, minval, maxval, seed = None) :\n",
    "        if seed : np.random.seed(seed)\n",
    "        val = np.random.uniform(maxval, minval)\n",
    "        self.init_value = val\n",
    "        self.update(session, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Creation Tools\n",
    "\n",
    "Create toy MC sample. To save memory, the sample is generated in \"chunks\" of a fixed size inside TF session, which are then concatenated.\n",
    "- **sess** : TF session                                                                                  \n",
    "- **pdf** : PDF graph                                                                                    \n",
    "- **x** : phase space placeholder used for PDF definition                                              \n",
    "- **phsp** : phase space                                                                                 \n",
    "- **size** : size of the target data sample (if >0) or number of chunks (if <0)                          \n",
    "- **majorant** : maximum PDF value for accept-reject method                                              \n",
    "- **chunk** : chunk size                                                                                 \n",
    "- **switches** : optional list of switches for component weights \n",
    "                                                                                                    \n",
    "Create toy MC sample using accept-reject method for a density defined as a graph                     \n",
    "- **density** : density graph\n",
    "- **x** : phase space placeholder used for density graph definition\n",
    "- **sample** : input uniformly distributed sample                                                       \n",
    "\n",
    "Returns numpy array of generated points                                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunToyMC(sess, pdf, x, phsp, size, majorant, chunk = 200000, switches = None, seed = None) :\n",
    "    first = True\n",
    "    length = 0\n",
    "    nchunk = 0\n",
    "    phsp_sample = phsp.Filter(x)\n",
    "\n",
    "    if seed : np.random.seed(seed)\n",
    "    while length < size or nchunk < -size :\n",
    "        initsample = phsp.UnfilteredSample(chunk, majorant)\n",
    "        d1 = sess.run ( phsp_sample, feed_dict = { x : initsample } )\n",
    "        d = CreateAcceptRejectSample(sess, pdf, x, d1)\n",
    "        if switches :\n",
    "            weights = []\n",
    "            v = sess.run(pdf, feed_dict = { x : d } )\n",
    "            for i in range(len(switches)) :\n",
    "                fdict = {}\n",
    "                for j in range(len(switches)) : fdict[switches[j]] = 0.\n",
    "                fdict[switches[i]] = 1.\n",
    "                fdict[x] = d\n",
    "                v1 = sess.run( pdf, feed_dict = fdict )\n",
    "                weights += [ v1/v ]\n",
    "            d = np.append(d, np.transpose(np.array(weights, dtype = np.dtype('f'))), axis = 1)\n",
    "        if first : data = d\n",
    "        else : data = np.append(data, d, axis = 0)\n",
    "        first = False\n",
    "        length += len(d)\n",
    "        nchunk += 1\n",
    "        print \"  Chunk %d, size=%d, total length=%d\" % (nchunk, len(d), length)\n",
    "    if size > 0 :\n",
    "        return data[:size]\n",
    "    else :\n",
    "        return data\n",
    "    \n",
    "def CreateAcceptRejectSample(sess, density, x, sample) :\n",
    "    p = np.transpose(np.transpose(sample)[:-1])\n",
    "    r = np.transpose(sample)[-1]\n",
    "    pdf_data = sess.run(density, feed_dict = {x : p})\n",
    "    return p[ pdf_data > r ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc TensorFlow interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sqrt(x) : return tf.sqrt(x)\n",
    "def Cos(x) : return tf.cos(x)\n",
    "def Integral(pdf) : return tf.reduce_mean(pdf)\n",
    "def UnbinnedNLL(pdf, integral) : return -tf.reduce_sum(tf.log(pdf/integral ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MINUIT implementation\n",
    "\n",
    "Perform MINUIT minimisation of the negative likelihood. \n",
    "\n",
    "- **sess** : TF session\n",
    "- **nll** : graph for negitive likelihood to be minimised\n",
    "- **feed_dict** :\n",
    "- **call_limit** : call limit for MINUIT\n",
    "- **gradient** : external gradient graph. If None and useGradient is not False, will be calculated internally         - **useGradient** : flag to control the use of analytic gradient while fitting:                          \n",
    "    - None or False   : gradient is not used\n",
    "    - True or \"CHECK\" : analytic gradient will be checked with finite elements, and will be used is they match\n",
    "    - \"FORCE\"         : analytic gradient will be used regardless. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheable_tensors = []\n",
    "def RunMinuit(sess, nll, feed_dict, call_limit = 50000, useGradient = True, gradient = None, printout = 50, tmpFile = \"tmp_result.txt\" ) :\n",
    "    global cacheable_tensors\n",
    "    tfpars = tf.trainable_variables()                      # Create TF variables                           \n",
    "    float_tfpars = [ p for p in tfpars if p.floating() ]   # List of floating parameters                   \n",
    "    if useGradient and gradient is None :\n",
    "        gradient = tf.gradients(nll, float_tfpars)            # Get analytic gradient                        \n",
    "\n",
    "    cached_data = {}\n",
    "\n",
    "    fetch_list = []\n",
    "    for i in cacheable_tensors :\n",
    "        if i not in cached_data : fetch_list += [ i ]\n",
    "    feeds = dict(feed_dict)\n",
    "    for i in cacheable_tensors :\n",
    "        if i in cached_data : feeds[i] = cached_data[i]\n",
    "\n",
    "    fetch_data = sess.run(fetch_list, feed_dict = feeds ) # Calculate log likelihood                       \n",
    "\n",
    "    for i,d in zip(fetch_list, fetch_data) :\n",
    "        cached_data[i] = d\n",
    "\n",
    "    feeds = dict(feed_dict)\n",
    "    for i in cacheable_tensors :\n",
    "        if i in cached_data : feeds[i] = cached_data[i]                                                                                         \n",
    "\n",
    "    def fcn(npar, gin, f, par, istatus) :                  # MINUIT fit function                           \n",
    "        for i in range(len(float_tfpars)) : float_tfpars[i].update(sess, par[i])\n",
    "        f[0] = sess.run(nll, feed_dict = feeds ) # Calculate log likelihood                                  \n",
    "        if istatus == 2 :            # If gradient calculation is needed                                     \n",
    "            dnll = sess.run(gradient, feed_dict = feeds )  # Calculate analytic gradient                       \n",
    "            for i in range(len(float_tfpars)) : gin[i] = dnll[i] # Pass gradient to MINUIT                     \n",
    "        fcn.n += 1\n",
    "        if fcn.n % printout == 0 :\n",
    "            print \"  Iteration \", fcn.n, \", Flag=\", istatus, \" NLL=\", f[0], \", pars=\", sess.run(float_tfpars)\n",
    "\n",
    "    fcn.n = 0\n",
    "    minuit = TVirtualFitter.Fitter(0, len(tfpars))        # Create MINUIT instance                         \n",
    "    minuit.Clear()\n",
    "    minuit.SetFCN(fcn)\n",
    "    arglist = array.array('d', 10*[0])    # Auxiliary array for MINUIT parameters                          \n",
    "\n",
    "    for n,p in enumerate(float_tfpars) :  # Declare fit parameters in MINUIT                               \n",
    "        step_size = p.step_size\n",
    "        lower_limit = p.lower_limit\n",
    "        upper_limit = p.upper_limit\n",
    "        if not step_size : step_size = 1e-6\n",
    "        if not lower_limit : lower_limit = 0.\n",
    "        if not upper_limit : upper_limit = 0.\n",
    "        minuit.SetParameter(n, p.par_name, p.init_value, step_size, lower_limit, upper_limit)\n",
    "\n",
    "    if useGradient == True or useGradient == \"CHECK\" :\n",
    "        minuit.ExecuteCommand(\"SET GRA\", arglist, 0)  # Ask analytic gradient                                \n",
    "    elif useGradient == \"FORCE\" :\n",
    "        arglist[0] = 1\n",
    "        minuit.ExecuteCommand(\"SET GRA\", arglist, 1)  # Ask analytic gradient                                \n",
    "    arglist[0] = call_limit                       # Set call limit                                         \n",
    "    minuit.ExecuteCommand(\"MIGRAD\", arglist, 1)   # Perform minimisation                                   \n",
    "\n",
    "    results = {}                                  # Get fit results and update parameters                  \n",
    "    for n,p in enumerate(float_tfpars) :\n",
    "        p.update(sess, minuit.GetParameter(n) )\n",
    "        p.fitted_value = minuit.GetParameter(n)\n",
    "        p.error = minuit.GetParError(n)\n",
    "        results[p.par_name] = ( p.fitted_value, p.error )\n",
    "\n",
    "    # Get status of minimisation and NLL at the minimum                                                    \n",
    "    maxlh = array.array(\"d\", [0.])\n",
    "    edm = array.array(\"d\", [0.])\n",
    "    errdef = array.array(\"d\", [0.])\n",
    "    nvpar = array.array(\"i\", [0])\n",
    "    nparx = array.array(\"i\", [0])\n",
    "    fitstatus = minuit.GetStats(maxlh, edm, errdef, nvpar, nparx)\n",
    "\n",
    "    # return fit results                                                                                   \n",
    "    results[\"loglh\"] = maxlh[0]\n",
    "    results[\"status\"] = fitstatus\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define FourBodyAngularPhaseSpace\n",
    "\n",
    "Generate uniform sample makes a number of points within some phase space.\n",
    "- **size** : number of _initial_ points to generate. Not all of them will fall into phase space, so the number of points in the output will be <size.\n",
    "- **majorant** : if majorant>0, add 3rd dimension to the generated tensor which is uniform number from 0 to majorant. Useful for accept-reject toy MC.\n",
    "\n",
    "Also defined is a condition and the mechanics to filter on this condition.\n",
    "\n",
    "**Note** *it does not actually generate the sample, but returns the data flow graph for generation, which has to be run within TF session.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourBodyAngularPhaseSpace :\n",
    "    def __init__(self) :\n",
    "        self.data_placeholder = self.Placeholder(\"data\")\n",
    "        self.norm_placeholder = self.Placeholder(\"data\")\n",
    "\n",
    "    def Inside(self, x) :\n",
    "        cos1 = self.CosTheta1(x)\n",
    "        cos2 = self.CosTheta2(x)\n",
    "        phi  = self.Phi(x)\n",
    "\n",
    "        inside = tf.logical_and(tf.logical_and(tf.greater(cos1, -1.), tf.less(cos1, 1.)), \n",
    "                            tf.logical_and(tf.greater(cos2, -1.), tf.less(cos2, 1.)))\n",
    "        inside = tf.logical_and(inside, \n",
    "                            tf.logical_and(tf.greater(phi, 0.), tf.less(phi, 2.*math.pi ))\n",
    "                           )\n",
    "        return inside\n",
    "\n",
    "    def Filter(self, x) :\n",
    "        return tf.boolean_mask(x, self.Inside(x) )\n",
    "        \n",
    "    def UnfilteredSample(self, size, majorant = -1) :\n",
    "        v = [\n",
    "              np.random.uniform(-1., 1., size ).astype('d'),\n",
    "              np.random.uniform(-1., 1., size ).astype('d'),\n",
    "              np.random.uniform(0., 2.*math.pi, size ).astype('d')\n",
    "                ]\n",
    "        if majorant>0 : v += [ np.random.uniform( 0., majorant, size).astype('d') ]\n",
    "        return np.transpose(np.array(v))\n",
    "\n",
    "        \n",
    "    def UniformSample(self, size, majorant = -1) :\n",
    "        return self.Filter( self.UnfilteredSample(size, majorant) )\n",
    "\n",
    "    def CosTheta1(self, sample) :\n",
    "        return tf.transpose(sample)[0]\n",
    "\n",
    "    def CosTheta2(self, sample) :\n",
    "        return tf.transpose(sample)[1]\n",
    "\n",
    "    def Phi(self, sample) :\n",
    "        return tf.transpose(sample)[2]\n",
    "\n",
    "    def Placeholder(self, name = None) :\n",
    "        return tf.placeholder(fptype, shape = (None, None), name = name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "phsp = FourBodyAngularPhaseSpace()\n",
    "\n",
    "FL  = FitParameter(\"FL\" ,  0.770,  0.000, 1.000, 0.01)\n",
    "AT2 = FitParameter(\"AT2\",  0.200, -1.000, 1.000, 0.01)\n",
    "S5  = FitParameter(\"S5\" , -0.100, -1.000, 1.000, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x) :\n",
    "    cosThetaK = phsp.CosTheta1(x)\n",
    "    cosThetaL = phsp.CosTheta2(x)\n",
    "    phi = phsp.Phi(x)\n",
    "\n",
    "    sinThetaK = Sqrt( 1.0 - cosThetaK * cosThetaK )\n",
    "    sinThetaL = Sqrt( 1.0 - cosThetaL * cosThetaL )\n",
    "\n",
    "    sinTheta2K =  (1.0 - cosThetaK * cosThetaK)\n",
    "    sinTheta2L =  (1.0 - cosThetaL * cosThetaL)\n",
    "\n",
    "    sin2ThetaK = (2.0 * sinThetaK * cosThetaK)\n",
    "    cos2ThetaL = (2.0 * cosThetaL * cosThetaL - 1.0)\n",
    "\n",
    "    pdf  = (3.0/4.0) * (1.0 - FL ) * sinTheta2K\n",
    "    pdf +=  FL * cosThetaK * cosThetaK\n",
    "    pdf +=  (1.0/4.0) * (1.0 - FL) * sin2ThetaK *  cos2ThetaL\n",
    "    pdf +=  (-1.0) * FL * cosThetaK * cosThetaK *  cos2ThetaL\n",
    "    pdf +=  (1.0/2.0) * (1.0 - FL) * AT2 * sinTheta2K * sinTheta2L * Cos(2.0 * phi )\n",
    "    pdf +=  S5 * sin2ThetaK * sinThetaL * Cos( phi )\n",
    "\n",
    "    return pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Graph!\n",
    "\n",
    "### Data and shape from phasespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ph = phsp.data_placeholder\n",
    "norm_ph = phsp.norm_placeholder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise tensor flow variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()  \n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum =  1.71372847246\n"
     ]
    }
   ],
   "source": [
    "norm_sample = sess.run( phsp.UniformSample(1000000) )\n",
    "majorant = EstimateMaximum(sess, model(data_ph), data_ph, norm_sample )*1.1\n",
    "print \"Maximum = \", majorant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Chunk 1, size=266793, total length=266793\n"
     ]
    }
   ],
   "source": [
    "data_sample = RunToyMC( sess, model(data_ph), data_ph, phsp, 10000, majorant, chunk = 1000000)\n",
    "norm = Integral( model(norm_ph) )\n",
    "nll = UnbinnedNLL( model(data_ph), norm )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 3, 'AT2': (0.04613023996759291, 0.11273485910265801), 'FL': (0.7717309583475085, 0.00857908507854227), 'S5': (-0.11507803557934504, 0.015583285157298121), 'loglh': -2333.305033661937}\n",
      " PARAMETER DEFINITIONS:\n",
      "    NO.   NAME         VALUE      STEP SIZE      LIMITS\n",
      "     1 FL           7.70000e-01  1.00000e-02    0.00000e+00  1.00000e+00\n",
      "     2 AT2          2.00000e-01  1.00000e-02   -1.00000e+00  1.00000e+00\n",
      "     3 S5          -1.00000e-01  1.00000e-02   -1.00000e+00  1.00000e+00\n",
      " **********\n",
      " **    1 **SET GRA\n",
      " **********\n",
      " FIRST CALL TO USER FUNCTION AT NEW START POINT, WITH IFLAG=4.\n",
      " CHECK OF GRADIENT CALCULATION IN FCN\n",
      "            PARAMETER      G(IN FCN)   G(MINUIT)  DG(MINUIT)   AGREEMENT\n",
      "           1          FL -2.6863e+01 -2.6863e+01  2.1460e-05    GOOD\n",
      "           2         AT2  2.4899e+01  2.4899e+01  2.8624e-07    GOOD\n",
      "           3          S5  1.3282e+02  1.3282e+02  1.6291e-05    GOOD\n",
      " **********\n",
      " **    2 **MIGRAD       5e+04\n",
      " **********\n",
      " START MIGRAD MINIMIZATION.  STRATEGY  1.  CONVERGENCE WHEN EDM .LT. 1.00e-04\n",
      " FCN=-2330.27 FROM MIGRAD    STATUS=INITIATE        1 CALLS           9 TOTAL\n",
      "                     EDM= unknown      STRATEGY= 1      NO ERROR MATRIX       \n",
      "  EXT PARAMETER               CURRENT GUESS       STEP         FIRST   \n",
      "  NO.   NAME      VALUE            ERROR          SIZE      DERIVATIVE \n",
      "   1  FL           7.70000e-01   1.00000e-02   2.37674e-02  -2.68631e+01\n",
      "   2  AT2          2.00000e-01   1.00000e-02   1.02064e-02   2.48991e+01\n",
      "   3  S5          -1.00000e-01   1.00000e-02   1.00506e-02   1.32822e+02\n",
      " MIGRAD MINIMIZATION HAS CONVERGED.\n",
      " MIGRAD WILL VERIFY CONVERGENCE AND ERROR MATRIX.\n",
      " COVARIANCE MATRIX CALCULATED SUCCESSFULLY\n",
      " FCN=-2333.31 FROM MIGRAD    STATUS=CONVERGED      41 CALLS          49 TOTAL\n",
      "                     EDM=8.0242e-06    STRATEGY= 1      ERROR MATRIX ACCURATE \n",
      "  EXT PARAMETER                                   STEP         FIRST   \n",
      "  NO.   NAME      VALUE            ERROR          SIZE      DERIVATIVE \n",
      "   1  FL           7.71731e-01   8.57909e-03   1.54213e-02   4.01157e-02\n",
      "   2  AT2          4.61302e-02   1.12735e-01   1.73550e-02   3.05859e-02\n",
      "   3  S5          -1.15078e-01   1.55833e-02   1.18130e-02   1.29276e-01\n",
      " EXTERNAL ERROR MATRIX.    NDIM=  25    NPAR=  3    ERR DEF=1\n",
      "  7.361e-05  1.331e-05  4.456e-06 \n",
      "  1.331e-05  1.276e-02 -1.119e-04 \n",
      "  4.456e-06 -1.119e-04  2.429e-04 \n",
      " PARAMETER  CORRELATION COEFFICIENTS  \n",
      "       NO.  GLOBAL      1      2      3\n",
      "        1  0.03692   1.000  0.014  0.033\n",
      "        2  0.06550   0.014  1.000 -0.064\n",
      "        3  0.07216   0.033 -0.064  1.000\n"
     ]
    }
   ],
   "source": [
    "result = RunMinuit(sess, nll, { data_ph : data_sample, norm_ph : norm_sample } )\n",
    "print result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
